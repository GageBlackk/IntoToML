{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwdprYHp2FH"
      },
      "outputs": [],
      "source": [
        "\n",
        "##Gage Black\n",
        "##Homework 6\n",
        "##ECGR 4105\n",
        "#Single and Multi\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "data_path = '../data-unversioned'\n",
        "cirfar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cirfar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqI-yanaqiQ9"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PanxfW_4B4pu"
      },
      "outputs": [],
      "source": [
        "##Ripped from files10 CIFARS\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIl4uNGOqnmk"
      },
      "outputs": [],
      "source": [
        "##Load the trainer\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "##Single Sequences\n",
        "seqSingle = nn.Sequential(\n",
        "  nn.Linear(3072, 512),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(512, 10),\n",
        "  nn.LogSoftmax(dim=1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yt5XANQ9Efxg"
      },
      "outputs": [],
      "source": [
        "##Multiple Sequences\n",
        "\n",
        "\n",
        "\n",
        "seqMulti = nn.Sequential(\n",
        "  nn.Linear(3072, 512),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(512, 256),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(256, 128),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(128, 10),\n",
        "  nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 0.01\n",
        "nEpochs = 300\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "optimizer_single = optim.SGD(seqSingle.parameters(), lr=learning_rate)\n",
        "optimizer_multi = optim.SGD(seqMulti.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtTmPY-zqnt1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lhXAmaEH-f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JATEBE50OTm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a4eb4f-19e5-4d1e-9a7d-28ce6386c895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1.6024\n",
            "Epoch 10, Loss 1.7445\n",
            "Epoch 20, Loss 1.1537\n",
            "Epoch 30, Loss 0.4073\n",
            "Epoch 40, Loss 0.0967\n",
            "Epoch 50, Loss 0.1502\n",
            "Epoch 60, Loss 0.1003\n",
            "Epoch 70, Loss 0.0168\n",
            "Epoch 80, Loss 0.0033\n",
            "Epoch 90, Loss 0.0016\n",
            "Epoch 100, Loss 0.0013\n",
            "Epoch 110, Loss 0.0021\n",
            "Epoch 120, Loss 0.0010\n",
            "Epoch 130, Loss 0.0008\n",
            "Epoch 140, Loss 0.0011\n",
            "Epoch 150, Loss 0.0012\n",
            "Epoch 160, Loss 0.0011\n",
            "Epoch 170, Loss 0.0012\n",
            "Epoch 180, Loss 0.0006\n",
            "Epoch 190, Loss 0.0005\n",
            "Epoch 200, Loss 0.0007\n",
            "Epoch 210, Loss 0.0009\n",
            "Epoch 220, Loss 0.0005\n",
            "Epoch 230, Loss 0.0010\n",
            "Epoch 240, Loss 0.0004\n",
            "Epoch 250, Loss 0.0004\n",
            "Epoch 260, Loss 0.0005\n",
            "Epoch 270, Loss 0.0004\n",
            "Epoch 280, Loss 0.0005\n",
            "Epoch 290, Loss 0.0003\n",
            "Epoch 300, Loss 0.0003\n"
          ]
        }
      ],
      "source": [
        "##EPoch in range of multi steps\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "  for imgs, labels in train_loader:\n",
        "\n",
        "    batch_size = imgs.shape[0]\n",
        "    outputs = seqMulti(imgs.view(batch_size, -1))\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optimizer_multi.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_multi.step()\n",
        "\n",
        "  if ((epoch == 1) or (epoch % 10 == 0)):\n",
        "    print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YErf274j_Zuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fb79c5-ccf3-4afb-c05b-bd796ca2e687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Layer Train Acc Percentage: 0.901880\n",
            "Single Layer Vali Acc Percentage: 0.469100\n",
            "Multi Layer Train Acc Percentage: 1.000000\n",
            "Multi Layer Valid Acc Percentage: 0.452100\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in train_loader:\n",
        "    outputs = seqSingle(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Single Layer Train Acc Percentage: %f\" % (correct / total))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "    outputs = seqSingle(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Single Layer Vali Acc Percentage: %f\" % (correct / total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in train_loader:\n",
        "    outputs = seqMulti(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Multi Layer Train Acc Percentage: %f\" % (correct / total))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "    outputs = seqMulti(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Multi Layer Valid Acc Percentage: %f\" % (correct / total))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}